import os, glob
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
import argparse

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--experiment', required=False, type=int, default=None, help='Path to the files')
    parser.add_argument('--results', required=False, type=int, default=None, help='Index for the files')
    args = parser.parse_args()

    experiment = args.experiment
    results = args.results
    if experiment == 1:
        freq = [0.025, 0.05, 0.10, 0.15, 0.20, 0.25]

        for i, f in tqdm(enumerate(freq[:5])):
            os.system("python ExtractData.py --index arxiv --minfreq "+str(freq[i])+" --maxfreq "+str(freq[i+1]) + " --freqs "+str(freq[i])+"-"+str(freq[i+1]))

    elif results == 1:
        path = os.getcwd()+"/results"
        for filename in glob.glob(os.path.join(path, 'vocabulary*.txt')):
            with open(os.path.join(path, filename), 'r') as f:
                vocab = {}
                for line in f:
                    key, value = line.split()
                    vocab[key] = int(value)
                print(filename)
                print(str(len(vocab.values())))
                hist, bins, _ = plt.hist(list(vocab.values()), density = False)  # density=False would make counts
                plt.show()
                logbins = np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins))
                plt.hist(list(vocab.values()), bins=logbins)
                plt.xscale('log')
                plt.yscale('log')
                plt.show()
                plt.hist(list(vocab.values()), density = False)  # density=False would make counts
                plt.show()
        for filename in glob.glob(os.path.join(path, 'document*.txt')):
            with open(os.path.join(path, filename), 'r') as f:
                data = f.read()
                data_into_list = data.split("\n")
                data_into_list = [int(i) for i in data_into_list]
                print(filename)
                print(sum(data_into_list) / len(data_into_list))
    elif experiment == 3:
        list_of_lists100 = [
        [30.445557117462158, 29.98080086708069, 30.56822943687439, 30.02667784690857 ],
        [16.181713342666626, 16.181713342666626, 15.875532865524292, 15.941356420516968],
        [11.941057205200195, 11.866257429122925, 12.14551067352295, 11.73061990737915],
        [9.784825086593628, 9.731966972351074, 9.51654314994812, 9.586356401443481],
        [10.67245078086853, 10.588675022125244, 10.619592189788818, 10.44306468963623],
        [10.427106857299805, 10.672451257705688, 10.65051007270813, 10.653501033782959],
        [11.026503801345825, 11.528161764144897, 11.485276699066162, 11.641858100891113],
        [11.434412717819214, 11.130226373672485, 11.230956554412842, 11.47929310798645]]

        row_average100 = [sum(sub_list) / len(sub_list) for sub_list in list_of_lists100]

        list_of_lists250 = [
        [62.06198287010193, 60.70062518119812, 60.85221838951111, 60.96890687942505],
        [32.82618951797485, 32.07021141052246, 32.12805652618408, 33.0032217502594],
        [22.454932689666748, 22.291370153427124, 22.302340745925903, 22.665369510650635],
        [18.32498002052307, 18.414741039276123, 17.97292160987854, 18.056698083877563],
        [19.235544443130493, 18.61320924758911, 18.360884428024292, 18.740867614746094],
        [18.95629119873047, 19.060014009475708, 19.247512578964233, 19.501832008361816],
        [19.45894742012024, 19.68334650993347, 19.37816286087036, 19.55668544769287],
        [20.082279443740845, 19.895777940750122, 20.13713264465332, 20.04537868499756]]

        row_average250 = [sum(sub_list) / len(sub_list) for sub_list in list_of_lists250]

        x = [1,2,3,4,5,6,7,8]

        fig,ax=plt.subplots()
        ax.plot(x, row_average100, marker="o", label="100 words")
        ax.set_xlabel("ncores")
        ax.set_ylabel("seconds")
        ax.plot(x, row_average250, marker="o", label="250 words")
        plt.legend(loc="upper right")
        plt.show()

    if experiment == 4:
        a = [[(0.4659022329511165, 'region'), (0.3130657815328908, 'temperatur'), (0.28455039227519613, 'line'), (0.2843995171997586, 'sourc'), (0.27926976463488234, 'emiss'), (0.22193723596861797, 'ratio'), (0.21333735666867834, 'identifi'), (0.1928183464091732, 'sim'), (0.18934821967410984, 'veloc'), (0.18844296922148462, 'origin')],
        [(0.37696969696969695, 'mechan'), (0.31287878787878787, 'understand'), (0.22454545454545455, 'test'), (0.22303030303030302, 'various'), (0.22166666666666668, 'found'), (0.21984848484848485, 'were'), (0.20363636363636364, 'control'), (0.19893939393939394, 'out'), (0.1962121212121212, 'character'), (0.18712121212121213, 'dure')],
        [(0.9876824817518248, 'without'), (0.21076642335766424, 'train'), (0.17039233576642335, 'need'), (0.1633211678832117, 'challeng'), (0.15784671532846714, 'dataset'), (0.15465328467153286, 'evalu'), (0.1539689781021898, 'novel'), (0.15237226277372262, 'task'), (0.1480383211678832, 'real'), (0.13982664233576642, 'thus')],
        [(0.7022052123200292, 'second'), (0.2633497357390195, 'same'), (0.21960998724257336, 'interest'), (0.2177874977218881, 'theoret'), (0.18352469473300528, 'give'), (0.1607435757244396, 'coupl'), (0.1594678330599599, 'them'), (0.15199562602515035, 'analyz'), (0.14853289593584837, 'about'), (0.1423364315655185, 'prove')],
        [(0.9505882352941176, 'oper'), (0.20380090497737557, 'quantum'), (0.18552036199095023, 'correspond'), (0.18389140271493212, 'implement'), (0.1714027149321267, 'extend'), (0.16162895927601809, 'construct'), (0.15656108597285068, 'defin'), (0.1534841628959276, 'novel'), (0.15058823529411763, 'evalu'), (0.1502262443438914, 'challeng')],
        [(0.3351470838292807, 'current'), (0.29093691549056283, 'imag'), (0.27053222241115454, 'thus'), (0.2647508927053222, 'multi'), (0.25522870260159836, 'class'), (0.25403842883863287, 'address'), (0.24689678626084, 'object'), (0.23618432239415066, 'challeng'), (0.22462166298248598, 'train'), (0.22292127189253527, 'dataset')],
        [(0.7180932854946181, 'approxim'), (0.43686998120621906, 'equat'), (0.1862292841277977, 'analyt'), (0.18400820092260378, 'dimension'), (0.18212882282590126, 'solv'), (0.1804202972834444, 'integr'), (0.17580727831881088, 'describ'), (0.17085255424568596, 'same'), (0.16145566376217324, 'standard'), (0.16094310609943618, 'finit')],
        [(0.528125, 'accuraci'), (0.5177884615384616, 'error'), (0.36033653846153846, 'mean'), (0.240625, 'train'), (0.20288461538461539, 'evalu'), (0.19158653846153847, 'dataset'), (0.18870192307692307, 'accur'), (0.18509615384615385, 'neural'), (0.17596153846153847, 'independ'), (0.17211538461538461, 'deep')],
        [(0.889487870619946, 'lower'), (0.38544474393531, 'bound'), (0.32443028669443763, 'size'), (0.17079147267826514, 'higher'), (0.15584415584415584, 'prove'), (0.15535407988238176, 'best'), (0.14947316834109287, 'found'), (0.14628767458956138, 'random'), (0.14555256064690028, 'constant'), (0.1399166870864984, 'factor')],
        [(0.6892892054182377, 'star'), (0.4845691942466136, 'stellar'), (0.46250523669878507, 'format'), (0.4484010613042871, 'galaxi'), (0.2915793883535819, 'survey'), (0.28292137969557324, 'evolut'), (0.2350230414746544, 'suggest'), (0.2077922077922078, 'sim'), (0.19257086999022482, 'line'), (0.1917329981846111, 'cluster')]]

        for i,sub_list in enumerate(a):
            print("CLASS"+str(i), end=" & ")
            for pair in sub_list:
                print(pair[1], end=", ")
            print("\\\\")

        b= [[(0.8619224641529474, 'current'), (0.1897681005487697, 'thus'), (0.17525225703664365, 'explor'), (0.16764029031687025, 'object'), (0.1646309081253319, 'identifi'), (0.16321472827049036, 'challeng'), (0.16055939104266242, 'imag'), (0.14622057001239158, 'out'), (0.14409630023012923, 'multi'), (0.1407328730748805, 'standard')],
        [(0.9902473834443387, 'chang'), (0.18030447193149382, 'dure'), (0.15199809705042816, 'temperatur'), (0.14105613701236916, 'evolut'), (0.14034253092293053, 'suggest'), (0.1384395813510942, 'correl'), (0.1367745004757374, 'describ'), (0.13582302568981922, 'understand'), (0.13415794481446242, 'out'), (0.131779257849667, 'mechan')],
        [(0.3683796951123684, 'mechan'), (0.25774005972025776, 'various'), (0.24862486248624863, 'test'), (0.22347949080622348, 'out'), (0.22316517366022318, 'understand'), (0.20744931636020744, 'follow'), (0.1995913877101996, 'imag'), (0.19786264340719786, 'character'), (0.18717586044318718, 'dure'), (0.1764890774791765, 'factor')],
        [(0.7097865144789685, 'extend'), (0.30522088353413657, 'associ'), (0.23441132952864088, 'thus'), (0.18452758402029168, 'identifi'), (0.18304798139928133, 'higher'), (0.1824138659902769, 'way'), (0.16296766011414077, 'correspond'), (0.15007398013105053, 'quantum'), (0.14943986472204607, 'oper'), (0.1492284929190446, 'construct')],
        [(0.5039882793423409, 'same'), (0.27885398013999674, 'theoret'), (0.269737913071789, 'interest'), (0.2129252808074231, 'second'), (0.20071626241250204, 'coupl'), (0.18915839166531012, 'give'), (0.17825166856584732, 'analyz'), (0.17564707797493082, 'them'), (0.1748331434152694, 'about'), (0.15464756633566662, 'bound')],
        [(0.9485338120885697, 'class'), (0.191901057251147, 'bound'), (0.16975862756832236, 'construct'), (0.16716537003790147, 'defin'), (0.1639736684619988, 'call'), (0.16297626171952923, 'correspond'), (0.1601835228406144, 'size'), (0.15559545182525433, 'exampl'), (0.15300219429483344, 'via'), (0.14961101137043686, 'oper')],
        [(0.9491680380325471, 'need'), (0.21740720424209178, 'implement'), (0.20497348692631193, 'without'), (0.19162552569025415, 'challeng'), (0.16529530078624977, 'evalu'), (0.1634668129456939, 'oper'), (0.15761565185591517, 'train'), (0.14957030535746937, 'real'), (0.14609617846041323, 'multipl'), (0.14335344669957945, 'current')],
        [(0.44007831072577264, 'approxim'), (0.329464410571948, 'accuraci'), (0.31478114948958186, 'evalu'), (0.29450426513774297, 'novel'), (0.2938050622290589, 'error'), (0.2477975108376451, 'size'), (0.23087680044748987, 'second'), (0.19857362606628443, 'train'), (0.1641728429590267, 'dataset'), (0.1606768284156062, 'challeng')],
        [(0.5459964236042122, 'found'), (0.32088217762765747, 'lower'), (0.3161136499105901, 'main'), (0.26783230677528314, 'were'), (0.25312934631432543, 'veri'), (0.22610768925094377, 'sourc'), (0.2088217762765746, 'aim'), (0.20445062586926285, 'near'), (0.16491158354857938, 'region'), (0.14563878402543215, 'temperatur')],
        [(0.7966355762824784, 'star'), (0.5917721518987342, 'format'), (0.2734843437708194, 'evolut'), (0.2476682211858761, 'suggest'), (0.24700199866755496, 'region'), (0.1997001998667555, 'object'), (0.18887408394403732, 'compon'), (0.18121252498334445, 'sourc'), (0.17721518987341772, 'indic'), (0.16688874083944039, 'main')]]
        # for i,sub_list in enumerate(a):
        #     print("CLASS"+str(i), end=" & ")
        #     for pair in sub_list:
        #         print(pair[1], end=" & ")
        #     print("\\\\")

        for i,sub_list in enumerate(b):
            print("CLASS"+str(i), end=" & ")
            for pair in sub_list:
                print(pair[1], end=", ")
            print("\\\\")
